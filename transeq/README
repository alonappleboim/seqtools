This script performs everything needed to transform a collection of
fastq files generated by the transeq protocol to many (optional)
different outputs.

Examples:
========

basic:
    python /cs/bd/tools/seqtools/transeq/main.py /my/fastq/path/

with k.lac alignemnt statistics:
    python /cs/bd/tools/seqtools/transeq/main.py /my/fastq/path/ -cip klactis:/cs/wetlab/genomics/klac/bowtie/genome

debugging pipeline (recommended before big runs, in this case runs on only 1e5 reads and 10 samples):
    python /cs/bd/tools/seqtools/transeq/main.py /my/fastq/path/ -d 100000,10

reporting stuff to your email(s):
    python /cs/bd/tools/seqtools/transeq/main.py /my/fastq/path/ -ue email1@some.domain,email2@same.domain

saving results to a specified path:
    python /cs/bd/tools/seqtools/transeq/main.py /my/fastq/path/ -ep ~/Dropbox/transeq_stats/

keeping unaligned reads:
    python /cs/bd/tools/seqtools/transeq/main.py /my/fastq/path/ -ku

keeping filtered, unaligned, and no-barcode reads:
    python /cs/bd/tools/seqtools/transeq/main.py /my/fastq/path/ -kf -ku -knb

restarting from fastq stage - TODO: CURRENTLY Not working!
    python /cs/bd/tools/seqtools/transeq/main.py -fp /previous/transeq/results/path/ -sa FASTQ


More Info:
=========
The implementation tries to use parallelization and efficient implementations
(i.e. heavylifting is not pythonic) as much as possible. The basic idea is to
split the work to samples, which are (mostly) independent, and collect all
results at the end.

The workflow is:
 parsing inputs and pre-processing
    performing all parsing tasks (samples, features, filters, exporters, etc), followed by all
    pre-processing steps - generating folders, making sure executables exist etc.

 splitting barcodes
    First pass with awk to make a file for every exact barcode match in the data. Quick and dirty.
    Second pass again with awk to collect sequences with upto a specified hamming distance from barcodes.
    The output is written to the tmp dir and is NOT in fastq format.
    There's an optional output file for no-barcode reads (-knb option).

 Next, a process is generated per sample that:
    - Transforms the previous stage output into regular gzipped fastq files.
    - Aligns reads to genome. Only aligned reads are further reported, an optional "unaligend" folder can be generated
      to hold all unaligned reads for further inspection (-ku option).
    - Filters reads according to specified filters (-F option). An optional "filtered" folder can be generated
      to hold all filtered reads for further inspection (-kf option).
    - If a count_index_paths (-cip) option is specified, the reads are also aligned to given genomes, and only
      statistics are reported (e.g. lactis alignment, human/ecoli alignment for contamination, etc.).
    - Generates strand-specific bigwig tracks per sample (.c.bw, and .w.bw).
    - For the given tts file, and specified window, reads are counted and reported per tts per sample.

 Finally, when all samples are done with sample-specific processing, the main process creates a hub (or not,
 -nh option), transfers the bigwig files to that location, and generates a link in the experiment output folder.
 Also the statistics and tts counts are exported to specified formats (-E option) in specified locations (-ep option)
